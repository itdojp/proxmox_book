# 執筆環境・検証環境の準備

本章では、本書の内容を実際に手を動かしながら追いかけるための環境づくりについて説明します。
読者が用意できるハードウェアや既存の仮想化基盤はさまざまですが、
ここでは「最低限この程度あれば本書の演習を一通り試せる」という目安と、
より踏み込んだ検証やクラスタ構成まで試したい場合の推奨構成を示します。

## 章のゴール

この章では、読者が自分の状況（手元PC・サーバ台数・既存の仮想化基盤）に合わせて、
本書のハンズオンを進めるための最小限のラボ構成を決められるようになることを目標とします。

## この章で分かること / 分からないこと

- 分かること:
  - 本書が前提とする Proxmox VE のバージョン
  - 単一ノード/3ノードクラスタ（ネスト可）のラボ構成パターン
  - 検証環境で事前に決めておくべき項目（命名、IP、DNS/NTP など）
- 分からないこと（後続章で扱います）:
  - インストーラの画面操作（第3章）
  - VM 作成やバックアップなど、Proxmox VE の具体的な操作手順（第4章以降）

## 対象バージョン（Proxmox VE 9.1）

本書のスクリーンショットと UI 手順は、原則として **Proxmox VE 9.1（9.x 系）** を前提にしています。
Proxmox VE 9.1 は Debian 13（Trixie）をベースとしており、標準のカーネルは 6.17 系です。

注意: Proxmox VE のバージョンアップでは、カーネル更新に伴ってドライバやカーネルモジュールの互換性問題が出ることがあります。
たとえば NVIDIA vGPU や LINSTOR/DRBD といった追加モジュールを利用する場合は、導入・更新前に公式の既知の問題を確認してください（例: `https://pve.proxmox.com/wiki/Roadmap` の “Known Issues & Breaking Changes”）。

## 最初に決めること（チェックリスト）

本書の手順は、ラボ環境の前提がぶれると途中で手戻りが発生します。
そこで、インストール作業に入る前に次の項目を決め、メモに残しておくことを推奨します。

- ノード構成: 単一ノードで進めるのか、3 ノードクラスタまで試すのか
- ホスト名（ノード名）: 例 `pve1` / `pve2` / `pve3`（章をまたいで参照するため、早めに固定する）
- 管理用 IP アドレス: 例 `192.168.10.11`（固定 IP を推奨）
- DNS/NTP: どこを参照するか（時刻ずれは証明書やクラスタ構成のトラブル原因になりやすい）
- ネットワーク分離: 管理用 / VM 用 / ストレージ用を分けるか（最初は 1 本でも開始可能）
- バックアップ退避先: 外付けディスク、NAS、別ホストなど（「別障害ドメイン」を意識する）

例（単一ノードラボ）:

- ノード: `pve1`
- 管理用ネットワーク: `192.168.10.0/24`（`pve1=192.168.10.11`）
- VM 用ネットワーク: 管理用と共用（最初は共用で開始し、必要なら VLAN で分離）

例（3 ノードクラスタラボ）:

- ノード: `pve1=192.168.10.11` / `pve2=192.168.10.12` / `pve3=192.168.10.13`
- 管理用ネットワーク（例 VLAN 10）と、VM/ストレージ用ネットワーク（例 VLAN 20/30）を分離（可能なら）

## 準備する PC / サーバのスペック

### 最低限のスペック（単一ノードで基本操作を試す）

まず、Proxmox VE を 1 台だけインストールし、仮想マシンの作成や基本操作を試すだけであれば、
次のようなスペックでも十分に学習を進められます。

- CPU: x86_64 対応 CPU（VT-x/AMD-V が有効であること）
- メモリ: 16 GB 以上（できれば 32 GB 以上）
- ストレージ: 500 GB 程度の SSD（SATA / NVMe は問わないが、SSD を推奨）
- ネットワーク: 1 GbE ポート 1 本以上

この構成であれば、いわゆる「自宅ラボ」向けの小型 PC や中古サーバでも十分に再現可能です。
複数の仮想マシンを同時に起動することを考えると、メモリは 16 GB よりも多いほど余裕が出ます。

### 推奨スペック（クラスタやストレージ検証を含めて試す）

クラスタ構成や Ceph などの分散ストレージも含めて検証したい場合は、
ある程度余裕のあるハードウェアを準備した方がスムーズです。
例えば、次のような構成が考えられます。

- CPU: 8 コア以上の x86_64 CPU
- メモリ: 64 GB 程度
- ストレージ:
  - Proxmox VE ノード用のシステムディスク（SSD）
  - VM 用データストアとしての SSD / HDD（複数台あると検証しやすい）
- ネットワーク:
  - 1 GbE ポート 2 本以上（管理用とストレージ／VM トラフィックを分けるイメージ）

このようなリソースを 1 台に集約し、後述する「ネスト構成のラボ」として利用することで、
物理サーバが 1 台しかない環境でも 3 ノードクラスタの挙動をある程度再現できます。

## 仮想化環境の選択肢

Proxmox VE を試すための「下側」の仮想化環境には、いくつかの選択肢があります。
本書では、次のようなパターンを代表例として扱います。

### 1. 物理サーバに直接インストールする（ベアメタル）

最もシンプルなのは、専用の物理サーバを用意して Proxmox VE を直接インストールする方法です。

- 利点:
  - 本番環境に近い構成で動作を確認できる
  - オーバーヘッドが少なく、性能評価もしやすい
- 注意点:
  - 物理サーバを占有する必要がある
  - 他の用途との兼用が難しい（既存のハイパーバイザと併用する場合は設計が必要）

本書では、スクリーンショットや画面遷移はベアメタルインストールを前提に説明しますが、
後述のネスト構成でもほぼ同じ手順で再現できます。

### 2. 既存のハイパーバイザ上にネスト構成で構築する

既に別の仮想化基盤（例: vSphere、Hyper-V、パブリッククラウド上のホスト型ハイパーバイザ）がある場合は、
その上に Proxmox VE の仮想マシンを 2〜3 台作成し、ネストされた環境として検証することもできます。

- 利点:
  - 追加の物理サーバを用意せずにクラスタや HA の挙動を試せる
  - スナップショットやテンプレートを活用して、検証環境を簡単に巻き戻せる
- 注意点:
  - ネスト構成の性能は本番と異なるため、性能評価の結果をそのまま本番に当てはめない
  - 上位ハイパーバイザ側でハードウェア支援仮想化を有効にする必要がある

本書で想定する 3 ノードクラスタのラボは、ネスト構成を前提として設計しています。

### 3. クラウド環境を利用する（必要に応じて）

一部のクラウド環境では、ベアメタルインスタンスやネスト構成を許容するインスタンス種別を利用して、
Proxmox VE を検証することも可能です。
ただし、クラウド環境でのライセンスや利用規約は必ず確認し、自己責任で利用してください。

## 本書で想定するラボ構成

本書では、次の 2 つのラボパターンを想定します。

### パターン A: 単一ノードラボ（基本編）

目的:
- インストール手順や基本的な VM 操作を一通り体験する。

構成イメージ:

- Proxmox VE ノード 1 台
- 管理用ネットワーク 1 本
- その上で複数の Linux/Windows VM を起動

このパターンは、Part I までの内容を追うのに十分です。
ストレージやネットワークもシンプルな構成で進められるため、最初の一歩として適しています。

### パターン B: 3 ノードクラスタ（発展編）

目的:
- クラスタ構成や HA、バックアップ／レプリケーションなど、Part II〜III の内容を実際に試す。

構成イメージ:

- Proxmox VE ノード 3 台（物理またはネスト構成）
- 共有ストレージとしての Ceph クラスタ、または共有ストレージに相当するストレージバックエンド
- 管理用ネットワークと、VM/ストレージ用ネットワーク（可能であれば分離）

ハードウェアが 1 台しかない場合でも、十分な CPU / メモリ / ストレージがあれば、
1 台の物理サーバの上に 3 台の Proxmox VE 仮想マシンを立てる形でこのパターンを再現できます。
後続のクラスタ／HA 章では、この 3 ノード構成を前提とした例を用います。

上記ラボ構成の概略は、`diagrams/part0/lab-topology.svg` に図としてまとめます。
本文中ではこの図を参照しながら、各ノードやネットワークの役割を説明していきます。

## 注意点（ストレージ・バックアップ）

Proxmox VE の検証環境といえども、ストレージとバックアップにはいくつか注意すべき点があります。

- システムディスクとデータディスクをできるだけ分ける  
  検証中に VM を大量に作成・削除すると、I/O が集中します。
  Proxmox VE 自体が動作しているシステムディスクとは別に、VM データ用のディスクを用意するとトラブルシュートがしやすくなります。
- SSD を優先的に利用する  
  特にネスト構成で複数ノードを同時に動かす場合、ストレージの速度がボトルネックになりがちです。
  可能な範囲で SSD を利用し、I/O の挙動を本番環境に近づけることを推奨します。
- バックアップ用の保存先をあらかじめ決めておく  
  外付けストレージや NAS、別ホスト上のバックアップサーバなど、バックアップデータを退避する場所を事前に決めておくと、
  Part III のバックアップ・レプリケーションの章にスムーズにつなげられます。
- 重要なデータを置かない  
  本書に沿って構築するラボ環境は、あくまで検証・学習用です。
  重要な業務データや本番環境のデータを保存することは避け、常に「いつでも作り直せる」前提で運用してください。

---

## まとめ

- 本書で想定するラボの前提として、ハードウェア要件の目安と検証方法（ベアメタル/ネスト/クラウド）を整理した。
- ラボ構成は「単一ノード（基本編）」と「3 ノードクラスタ（発展編）」の 2 パターンを想定し、学習範囲に応じて選べる。
- ストレージとバックアップは、I/O の集中や復旧の観点から、ディスク構成・保存先・データの扱いに注意して設計する。

次の章以降では、このラボ環境を前提として Proxmox VE のインストールや基本操作、クラスタ構成などを順に見ていきます。
