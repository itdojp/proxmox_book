# 第2章　アーキテクチャと主要コンポーネント

## 章のゴール

この章では、Proxmox VE を「いくつかの層（レイヤー）と主要コンポーネントの組み合わせ」として捉えられるようになり、
後続章の設定手順やトラブルシュートで「いま何を触っているのか」を見失わないことを目標にします。

## この章で分かること / 分からないこと

- 分かること:
  - Proxmox VE を構成する主要コンポーネントと役割（概略）
  - どの機能がどのレイヤーに属するか（ストレージ/ネットワーク/クラスタ等）
- 分からないこと（後続章で扱います）:
  - 画面操作の具体的な手順（どの画面で何を入力するか）
  - 個々のサービスの詳細設定・チューニング・ログの読み解き

## 用語メモ（本章でよく出る言葉）

- ノード: Proxmox VE が動作しているサーバ
- クラスタ: 複数ノードをまとめて管理・運用する構成
- `/etc/pve`: クラスタで共有される設定情報を参照できる領域（仕組みの詳細は深掘りしない）
- クォーラム: クラスタが「多数派を満たしている」かどうかの判断に使う考え方

## 本章のねらい

本章では、Proxmox VE を構成する主要なコンポーネントと、その役割・関係性を整理します。
具体的な設定手順に入る前に、どのサービスが何を担当しているのかを理解しておくことで、
トラブルシュートや設計判断を行いやすくすることが目的です。

## 主なコンポーネントと役割

Proxmox VE の内部では、いくつかのサービスやコンポーネントが連携して動作しています。
代表的なものと役割を、概略として以下に示します。

- Proxmox VE API／Web インターフェース  
  Web UI と REST API を提供し、ユーザーからの操作を受け付けます。
  仮想マシン／コンテナの作成・設定変更、ノードやクラスタの管理など、多くの操作はここを経由します。

- QEMU/KVM（仮想マシン）  
  フル仮想化の仮想マシンを実行するハイパーバイザ部分です。
  CPU・メモリ・ディスク・ネットワークといったリソースを仮想マシンに割り当てて動作させます。

- LXC（コンテナ）  
  OS コンテナ型の仮想化を提供します。
  軽量なコンテナ環境を、仮想マシンと同じ管理 UI から扱うことができます。

- pve-cluster（クラスタ管理）  
  ノード間で設定情報を共有し、一貫したクラスタ構成を維持するためのコンポーネントです。
  ノードが複数台ある場合でも、同じ設定やリソース定義を参照できるようにします。

- corosync（クラスタ通信・メンバーシップ）  
  クラスタ内のノード間通信やメンバーシップ管理に利用されます。
  ノードの生死やクォーラムの状態を監視し、HA の土台となる情報を提供します。

- ストレージスタック（LVM、ZFS、Ceph など）  
  仮想マシンやコンテナのディスクをどこに、どのような形で保存するかを担います。
  ローカルストレージ、共有ストレージ、分散ストレージなど、複数の選択肢があり、
  どの方式を選ぶかは設計上の重要なポイントになります。

- ネットワーク（Linux ブリッジ、ボンド、VLAN）  
  仮想マシンやコンテナにネットワーク接続を提供します。
  Linux ブリッジをベースに、ボンディングや VLAN タグなどを組み合わせて構成します。

これらのコンポーネントの関係性は、`diagrams/part1/ch2/architecture.svg` の図としてまとめます。

## 全体アーキテクチャのイメージ

Proxmox VE の典型的な構成を、概念的に整理すると次のような層構造として捉えられます。

- ハードウェア層  
  物理サーバ、CPU／メモリ、ローカルディスク、ネットワークインターフェースなど。

- ホスト OS と仮想化基盤層  
  Proxmox VE が提供するホスト OS、KVM／LXC、クラスタ管理コンポーネント（pve-cluster、corosync など）。

- ストレージ・ネットワークサービス層  
  LVM や ZFS、Ceph などのストレージバックエンド、および Linux ブリッジ／ボンド／VLAN によるネットワーク構成。

- ゲスト層（VM／コンテナ）  
  実際の業務システムや検証環境の OS・アプリケーションが動作する階層。

本書では、具体的な設定例やトラブルシュートの説明を行う際に、
どの層のどのコンポーネントに注目しているのかを意識しながら解説していきます。

## クラスタと HA に関わる要素

クラスタ構成や高可用性 (HA) を理解するうえで重要な要素を、ここで簡単に整理しておきます。
詳細な設定手順やシナリオは、Part III のクラスタ・HA 章で扱います。

- クォーラム  
  クラスタ内で「正常に動いているノードの多数派」が存在するかどうかを判断する仕組みです。
  corosync を通じてノード間の状態が共有され、クォーラムが失われた場合には危険な操作が抑制されます。

- フェンシング／ノード障害時の扱い  
  障害が発生したノードに対して、どのようにリソースを切り離すか、どのように再起動させるかといった方針を指します。
  実環境では外部電源装置や管理インターフェースと連携することもありますが、
  本書のラボでは、主にシンプルな構成で概念と挙動を確認します。

- リソース（VM／コンテナ）の HA ポリシー  
  どのリソースを HA 対象とするか、どのノードを優先的に利用するかといった設定です。
  Proxmox VE の Web UI から、対象 VM／コンテナごとに HA の有効化やグループ設定を行います。

これらの要素は、後続のクラスタ・HA 章でラボシナリオとともに詳しく扱いますが、
ここでは「どのコンポーネントが土台になっているか」を大まかに把握しておけば十分です。

## ストレージ構成との関係

Proxmox VE のアーキテクチャを理解するうえで、ストレージの扱いも重要です。
本書では、ストレージの詳細は Part II のストレージ章で解説しますが、
ここではアーキテクチャとの関係を簡単に触れておきます。

- ローカルストレージ  
  各ノード内のディスクを、LVM や ZFS などで管理し、仮想マシンのディスクを格納する構成です。
  単一ノード構成ではシンプルですが、クラスタでの共有・移動には工夫が必要です。

- 共有ストレージ／分散ストレージ  
  Ceph などの分散ストレージを利用することで、複数ノードから同じストレージプールにアクセスし、
  ライブマイグレーションや HA を前提とした設計が行いやすくなります。

- ストレージとバックアップ  
  バックアップやレプリケーション機能は、ストレージ構成と密接に関係します。
  バックアップ対象の保存先、ネットワーク帯域、復旧時間の要件などを踏まえて設計する必要があります。

これらの話題は、後続のストレージ・バックアップの章で具体的な設定例とともに掘り下げます。

## 本章のまとめと後続章との関係

本章では、Proxmox VE を構成する主要コンポーネントと、その役割・関係性を概観しました。
以降の章では、ここで紹介したコンポーネントを前提として、
インストール手順、基本操作、ストレージ・ネットワーク設計、クラスタ・HA、バックアップといったトピックを順に扱っていきます。

詳細な設定やチューニングに入る際には、必要に応じて本章の図（`diagrams/part1/ch2/architecture.svg`）やコンポーネント一覧を参照し、
「今どのレイヤー・どのサービスを触っているのか」を意識しながら読み進めてください。
